---
layout: page
title: Yet Another MNIST classification project
subtitle: 
bigimg: /img/mnist.png
---

<p class="used_tools">Key tools: python, pytorch </p>

<p align="right">
<br>You can access the github repository <a href="https://github.com/ymentha14/DeepLClassifWeightSharing"> here </a><br>
</p>

## Introduction

The present repository aims at presenting (yet another..) MNIST classification method, but tries to avoid state of the art pretrained models and rather implement the following features, as a deepL challenge and in order to assess whether Genetic Algorithm perform as well as GridSearch on a toy dataset.

## Implementation
A particular focus was put on the hyperparameter optimization methods: genetic algorithms were implemented following the method described in <a href="https://link.springer.com/article/10.1007/BF00175354"> this paper</a>.
<div align= "middle">
<img src="/img/mnist_arch.png" />
</div>
<br>
<i> Many architectures were explored in order to compare digits, both by first classifying the digits and then comparing it, and keeping logits of both pipelines in a double architecture. </i>


