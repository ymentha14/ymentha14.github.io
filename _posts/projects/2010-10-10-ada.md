---
layout: page
title: Data Awareness Dunnhumby dataset
subtitle: 
bigimg: /img/supermarket.jpg
---



<p align="right">
<i>In collaboration with Raphael Reis, Daniel Pechao and Jérôme Lüscher</i><br>You can access the full data story <a href="https://raphaelreis.github.io/ADA_project/#/"> here </a><br></p>


<p class="used_tools">Key tools: python, nltk, gensim, plotly, git, networkx</p>

## Introduction
We proposed an in-depth analysis of the complete-journey [dunnhumby dataset](https://www.dunnhumby.com/careers/engineering/sourcefiles): a file gathering information about consumer behaviors and demographic information for the dunnhumby supermarket chain. <br>

## Implementation
Since more than 90% of our data consisted of food items, we were naturally interested in scrapping the nutritional values for each item of our dataset, since these were not present. I personally cared for this section,developping a recursive algorithm associating any food article of our dataset to the semantically closest corresponding article in an equivalent <a href="https://fdc.nal.usda.gov/">database</a> from the U.S department of agriculture (USDA) which in turn did have nutritional values of interest. <br>

For instance, the article “Fondue fromage gruyere” of the dunnhumby dataset was to be associated with “art. 34 fondue moitié-moitié” rather than “Pizza fromage gruyere” in the USDA dataset since in the former case, the nutritional values would indeed fit better.
The following parsing algorithm was therefore developed in order to analyze and associate the words of any article:

<img src= "/img/rec_algo.jpg">
The challenge consisted mainly in defining a score metric for the item words, since some words describe “nutritionally” better the articles  than others (_for instance in “pizza olive and oil”, “pizza” turns out to be the most relevant word_). <br>


This preprocessing allowed me to perform further analysis, including an outlier estimation highlighting the households presenting potential risky consumption behaviors. Some of the computed statistics are displayed below, and are part of the whole data story.

### Nutrient responsability
Each item brings a certain proportion of the total mass of a given nutrient: we sort these items according to this proportion in order to gain insights on which item is mostly responsible for a nutrient consumption.
{% include nutrient_responsability.html %}
It turns out that most of the sodium consumption comes from the white bread and the cheese.

### Items sorted by sold mass
Nutrient values per 100g for the items sorted by the most bought mass, i.e. the items for which the biggest mass has been sold.
{% include Mass_sorted_items.html %}
Notice the responsability of eggs milk and meat for the cholesterol present in the population.

### Outliers detection
After having computed the _average soup_ of each household (i.e. the average nutritional intake per 100g), we applied PCA on the 10 nutrients in order to represent the household in a lower dimensional space. Using Inter-quantile-range outlier detection, we can isolate the households for which the average consumption of a given nutrient is potentially problematic (highlighted in red).
{% include Outliers_detection.html %}
It turns out that the first principal component is strongly correlated with energetic value while the second corresponds to fat for low values and sugar for high values. The id attribute is set wrt the household.

### Retrospective Improvements
A better method in order to match items from the dunnhumby dataset with one from the USDA would have consisted in using a Glove model (_Global Vectors for Word Representation _) trained on a bigger food-related dataset in order to obtain a vector-space representation of each words where the euclidean distances would be correlated with the semantic ones.

The rest of the project consisted in developing and maintaining the project blog that you can access in its totality on the following <a href="https://raphaelreis.github.io/ADA_project/#/"> link</a>.
